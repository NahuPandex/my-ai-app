# ü§ñ AI Chat App - React + Node.js + Llama 3

Este es un proyecto Full Stack que utiliza **React** para el frontend y **Node.js (Express)** para el backend. La aplicaci√≥n se conecta con los modelos de **Meta Llama 3** a trav√©s del router de **Hugging Face**, permitiendo tener un chat inteligente funcional de manera gratuita y eficiente.

---

## üöÄ Caracter√≠sticas
* **Frontend:** Interfaz moderna construida con React y Vite.
* **Backend:** Servidor en Express que act√∫a como puente seguro hacia la API de Hugging Face.
* **IA:** Integraci√≥n con Llama-3.1-8B-Instruct.
* **Seguridad:** Uso de variables de entorno para proteger tokens sensibles.

---

## üõ†Ô∏è Tecnolog√≠as utilizadas

**Frontend:**
* React.js
* CSS3 (Dise√±o responsivo)
* Fetch API

**Backend:**
* Node.js & Express
* OpenAI SDK (configurado para Hugging Face)
* Dotenv (gesti√≥n de variables)
* CORS

---

## üì¶ Instalaci√≥n y Configuraci√≥n

Sigue estos pasos para correr el proyecto localmente:

### 1. Clonar el repositorio
```bash
git clone [https://github.com/tu-usuario/tu-repositorio.git](https://github.com/tu-usuario/tu-repositorio.git)
cd tu-repositorio
2. Configurar el Backend
Entra a la carpeta del servidor (o ra√≠z):

Bash
npm install
Crea un archivo .env en la ra√≠z y agrega tus credenciales:

Fragmento de c√≥digo
PORT=8000
HF_TOKEN=tu_token_de_hugging_face_aqui
3. Configurar el Frontend
Ve a la carpeta del frontend (si est√° separada) e instala las dependencias:

Bash
npm install
Crea un archivo .env para el frontend:

Fragmento de c√≥digo
VITE_API_URL=http://localhost:8000/api/ai/generate
4. Ejecutar el proyecto
Correr Backend: npm run dev (o node index.js)

Correr Frontend: npm run dev

üõ°Ô∏è Notas sobre seguridad
Este proyecto utiliza un archivo .gitignore para evitar que las claves de API (.env) se suban a GitHub. Aseg√∫rate de generar tu propio token en Hugging Face.

‚úíÔ∏è Autor
Nahuel David Medina- github.com/NahuPandex